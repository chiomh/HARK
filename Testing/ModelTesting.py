"""
This file implements a wrapper class (called parameterCheck) to initialize and solve a model
for many different parameter values.  It then returns as output the 
errors generated by solving the model for those parameter values (if any.)
"""

# First, tell Python what directories we will be using
import sys
import os
sys.path.insert(0, os.path.abspath('../'))
sys.path.insert(0, os.path.abspath('../ConsumptionSaving'))
sys.path.insert(0, os.path.abspath('./'))

# Bring in modules we need
import traceback
import sys
import itertools
import numpy as np


class parameterCheck(object):
    '''
    A wrapper for an AgentType object (a model). This class automates  
    testing over a range parameter inputs by generating and testing sets of 
    parameters based on the original parameters.
    '''
    
    def __init__(self, model, base_primitives, multiplier = .1, N_param_values_in_range = 2):
        '''        
        model: an instance of AgentType with a working .solve() function
        
        base_primitives: a dictionary of input parameters for the the model
        
        multiplier: coefficient that determines the range for each parameter 
        within testing sets.  
        the range for each parameter P is [P-P*multiplier,P+P*multiplier].  All 
        testing parameters will be within this range
        
        N_param_ values_in_range: number of different parameter values to test within the given range
        '''
        self._model            = model
        self._base_primitives  = base_primitives
        self._multiplier       = multiplier
        
        self.N_param_values_in_range        = N_param_values_in_range
        self.dict_of_min_max_and_N          = self.makeParameterIterator()
        self._testParams       = self.findTestParameters()
        
        self.test_results      = []
        self.validParams       = []
        self.failedParams      = []

    def makeParameterIterator(self):
        '''
        create an object that contains all the information needed to generate 
        sets of parameters for testing
        
        returns a dictionary that specifies the min, max, and number of values to check
        for each parameter
        
        '''
        dict_of_min_max_and_N = {key:(value-self._multiplier*value,  # the min
                                      value+self._multiplier*value,  # the max
                                      self.N_param_values_in_range)  # number of param values to try
                                      for key,value in self._base_primitives.iteritems()}

        N_combinations = self.N_param_values_in_range**len(self._base_primitives)

        print("There are " + str(N_combinations)+ " parameter combinations to test.")

        return dict_of_min_max_and_N
        
    def findTestParameters(self):
        '''
        this function creates sets (dictionaries) of parameters to test in the model
        
        returns a list of parameter sets (dictionaries) for testing
        '''
        parameterLists = []
        keyOrder       = []
        testParams     = []
        for key,value in self.dict_of_min_max_and_N.iteritems():
            parameterRange = np.linspace(*value)
            parameterLists.append(parameterRange)
            keyOrder.append(key)
        for param_combination in itertools.product(*parameterLists):
            testParams.append(dict(zip(keyOrder,param_combination)))

        return testParams
    
    def testParameters(self):
        '''
        Runs the model on the test parameters and stores the error results.
        Also prints out the error messages that were thrown.
        '''        

        self.runModel(self._testParams)
        self.printErrors()
        
    def narrowParameters(self):
        '''
        this function needs to be able to identify the valid parameter space

        then it can plug in those values to the makeParameterIterator function and rerun the models        
        
        self._iterator = self.makeParameterIterator()
        
        parameterLists = []
        for k,v in self._iterator.iteritems():
            parameterRange = np.arange(*v)
            parameterLists.append(parameterRange)
        pairwise = list(all_pairs(parameterLists, previously_tested=self._testedParams))
        print("Subsequent round of testing reduced to " + str(len(pairwise)) + " pairwise combinations of parameters")
        
        self.runModel(pairwise)
        '''
        pass
    
    def runModel(self,parametersToTest):
        '''
        run the model using each set of test parameters.  for each model, a new
        object (an instance of parameterInstanceCheck) records the results of
        the test.  
        
        Each result is places in the appropriate list (failedParams or validParams)
        '''
        for i in range(len(parametersToTest)):
            tempDict   = dict(self._base_primitives)
            tempParams = parametersToTest[i]
            testData   = parameterInstanceCheck(i,tempParams,tempDict)
            Test       = self._model(**tempParams)
            print('Attempting to solve with parameter set ' + str(i))   
            try:
                Test.solve()
            #TODO: Insert allowed exceptions here so they don't count as errors!
            except Exception,e:
                testData.errorBoolean    = True
                testData.errorCode       = str(e)
                testData._tracebackText  = sys.exc_info()
            self.test_results.append(testData)
          
        for i in range(len(self.test_results)):
            if self.test_results[i].errorBoolean:
                self.failedParams.append(self.test_results[i])
            else:
                self.validParams.append(self.test_results[i])
                
    def printErrors(self):
        '''
        print out the test numbers and error codes for all failed tests
        '''
        for i in range(len(self.test_results)):
            if self.test_results[i].errorBoolean:
                print("test no " + str(i) + " failed with the following error code:")
                print(self.test_results[i].errorCode)

    def printTestResults(self,test_number):
        print("-----------------------------------------------------------------------")
        print("Showing specific results for test number " + str(test_number))
        #get a test result and find out more info
        test = TBSCheck.test_results[test_number]
        print("the test number is : " + str(test.testNumber))
        print("")
        print("the test parameters were : " + str(test.tested_primitives))
        print("")
        print("the error code is : " + str(test.errorCode))
        print("")
        print("the traceback for the error looked like : ")
        test.traceback()
     
   
class parameterInstanceCheck(object):
    '''
    this class holds information for a single test of a model
    '''
    def __init__(self,testNumber,base_primitives,original_primitives,errorBoolean=False,
                 errorCode=None,tracebackText=None):
        '''
        testNumber: the test number
        
        base_primitives: the set of parameters that was tested
        
        original_primitives: the original parameters that test parameters were constructed from
                    
        errorBoolean: boolean indicator of an error    

        errorCode: text of the error (exception type included)
        
        tracebackText: full traceback, printable using the traceback.prin_excpetino function
        
        '''
        
        self.testNumber          = testNumber
        self.original_primitives = original_primitives
        self.tested_primitives   = base_primitives
        self.errorBoolean        = errorBoolean
        self.errorCode           = errorCode
        self._tracebackText      = tracebackText
        
        
    def traceback(self):
        '''
        function that prints a traceback for an errror
        '''
        try:
            traceback.print_exception(*self._tracebackText)
        except TypeError:
            print("The test was run successfully - no error generated")
            
            
if __name__ == '__main__': 
    """
    Solve the Tractable Buffer Stock model for many different parameter values, keeping
    track of when the model generates an error.
    """

    # Bring in the TractableBufferStockModel to test it
    import TractableBufferStockModel as Model
    
    
    base_primitives = {'UnempPrb' : .015,
                       'DiscFac' : 0.9,
                       'Rfree' : 1.1,
                       'PermGroFac' : 1.05,
                       'CRRA' : .95}
                       
    # Assign a model and base parameters to be checked
    TBSCheck = parameterCheck(Model.TractableConsumerType,base_primitives)
    
    #run the testing function.  This runs the model multiple times
    TBSCheck.testParameters()
    
    TBSCheck.printTestResults(4)    
    
